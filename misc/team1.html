<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Ethical Reflections Team1</title>
   	<link rel="stylesheet" href="../styles/minimal-table.css" type="text/css">
</head>

<body>
<!-- Site navigation menu -->
<ul class="navbar">
  <li><a href="../index.html">Home</a>
  <li><a href="ethics.html">Ethical Reflections</a> 
  <li><a href="process.html">Process Support</a>
</ul>

<h1>Ethical Reflections Team Member 1</h1><br>
<p>Team name 1608</p>

<p><h4>Student name: Xiaofeng Wang, id:19070130, </p></h4>

<p><h5>Ethical Reflection</p></h5>
<p>There is a major ethical issue with the development of medical robots firstly is the idea of the possible loss of personalized health care, for the most part this is about how that there is no sense of care in a robot compared to a human where robots are used to replace nurses and carers making humans feel likes objects, this in turn will reflect the idea of the loss of human contact where the robot has no feelings compared to a human doing things. An example of this is Alzheimers is more likely to be developed in people with a lack of social interactions, this means that it is more likely to happen to people that are being taken care of by medical robotics, reinforcing the idea that robots will result in the lack of social interaction with elderly people. A fix for this ethical concern, where robots will work alongside medical staff and caregivers, in such a method that will allow the best of both worlds. Another ethical concern is medical robots having the capabilities of being autonomous, controlled and their controllability. In such ways, who will or should control the robot, meaning that it will carry out tasks specified by the user. The idea of a “responsibility gap”, It is defined as if they can change the rules by which they act then not the humans but the robots should be held responsible for their autonomous decisions.” This is defined as that robots that would allow a human system be adapted to modulate robot behaviour. Patients may not be psychologically satisfied with non-human interactions this means that human emotional responses to machines may in fact impact their cognitive responses, this will result in that the perceived notions of real and metaphorical or difference may equate to less trust of the medical robot and lower willingness to share personal information. This will respond whether logical or not can subsequently result in a negative interaction , this has been seen throughout recent history such that negative interaction with healthcare workers or healthcare systems result in negative healthcare outcomes thus the emotional underpinning of successful doctor patient relations and communications. The developments of robots that interact with human store information on cloud servers mean that this data can be misused and data breaches can occur and personal information can be leaked thus data privacy and key ethical and legal issues furthermore this mean that data stored on the server are vulnerable to malicious actors and remote attacks. One final idea is the idea that Aristotle's virtue ethics is defined as morality assumes that we acquire virtue through practice. By practicing being honest, brave, just, generous, and so on, a person develops an honorable and moral character, this is reflected in  robots may have other motivations such as maximising profits, reducing patient interaction times, minimizing their potential liability, and allocating their resources according to their own needs and interests. This helps to summarize the ethics behind medical robots and the question that arise throughout modern society and how medical robots will affect everyday life.</p>
<p><h6>Personal Reflection</p></h6>





		




</html>